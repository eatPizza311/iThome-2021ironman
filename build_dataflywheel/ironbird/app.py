### Script for Ironman 2021
import os
import json
import requests
import SessionState
import streamlit as st
import tensorflow as tf
from utils import load_and_prep_image, classes_and_models, update_logger, predict_json

# Setup environment credentials (you'll need to change these)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "ironman-327706-ba995652161d.json" # change for your GCP key
PROJECT = "ironman-327706" # change for your GCP project
REGION = "asia-east1" # change for your GCP region (where your model is hosted)

### Streamlit code (works as a straigtht-forward script) ###
st.title("æ­¡è¿ä¾†åˆ° Iron bird ğŸ¦…")
st.header("çœ‹çœ‹ä½ çš„ç…§ç‰‡æ˜¯ä»€éº¼é³¥!?")

@st.cache # cache the function so predictions aren't always redone (Streamlit refreshes every click)
def make_prediction(image, model, class_names):
    """
    Takes an image and uses model (a trained TensorFlow model) to make a
    prediction.

    Returns:
     image (preproccessed)
     pred_class (prediction class from class_names)
     pred_conf (model confidence)
    """
    image = load_and_prep_image(image)
    # Turn tensors into int16 (saves a lot of space, ML Engine has a limit of 1.5MB per request)
    image = tf.cast(tf.expand_dims(image, axis=0), tf.int16)
    # image = tf.expand_dims(image, axis=0)
    preds = predict_json(project=PROJECT,
                         region=REGION,
                         model=model,
                         instances=image)
    pred_class = class_names[tf.argmax(preds[0])]
    pred_conf = tf.reduce_max(preds[0])
    return image, pred_class, pred_conf

# Pick the model version
choose_model = st.sidebar.selectbox(
    "é¸æ“‡æ¨¡å‹å“¦",
    ("Model 1 (10 ç¨®é³¥é¡)", # original 10 classes
     "Model 2 (11 ç¨®é³¥é¡)", # original 10 classes + ASIAN CRESTED IBIS
     "Model 3 (11 ç¨®é³¥é¡ + éé³¥é¡)") # 11 classes (same as above) + NOT_BIRDS class
)

# Model choice logic
if choose_model == "Model 1 (10 ç¨®é³¥é¡)":
    CLASSES = classes_and_models["model_1"]["classes"]
    MODEL = classes_and_models["model_1"]["model_name"]
elif choose_model == "Model 2 (11 ç¨®é³¥é¡)":
    CLASSES = classes_and_models["model_2"]["classes"]
    MODEL = classes_and_models["model_2"]["model_name"]
else:
    CLASSES = classes_and_models["model_3"]["classes"]
    MODEL = classes_and_models["model_3"]["model_name"]

# Display info about model and classes
if st.checkbox("æƒ³çœ‹å¯è¾¨è­˜çš„é³¥å…’æœ‰å“ªäº›ï¼Ÿ"):
    st.write(f"ä½ é¸æ“‡çš„æ¨¡å‹æ˜¯ {MODEL}, é€™è£¡æ˜¯å®ƒå¯ä»¥è¾¨åˆ¥å‡ºä¾†çš„é³¥å…’ç¨®é¡:\n", CLASSES)

# File uploader allows user to add their own image
uploaded_file = st.file_uploader(label="ä¸Šå‚³é³¥ç…§å§...ğŸ¤­",
                                 type=["png", "jpeg", "jpg"])

# Setup session state to remember state of app so refresh isn't always needed
# See: https://discuss.streamlit.io/t/the-button-inside-a-button-seems-to-reset-the-whole-app-why/1051/11 
session_state = SessionState.get(pred_button=False)

# Create logic for app flow
if not uploaded_file:
    st.warning("è«‹çµ¦æˆ‘ä¸€å€‹åœ–ç‰‡å•¦ï¼ï¼")
    st.stop()
else:
    session_state.uploaded_image = uploaded_file.read()
    st.image(session_state.uploaded_image, use_column_width=True)
    pred_button = st.button("é–‹å§‹é æ¸¬ï¼")

# Did the user press the é–‹å§‹é æ¸¬ï¼ button?
if pred_button:
    session_state.pred_button = True 

# And if they did...
if session_state.pred_button:
    session_state.image, session_state.pred_class, session_state.pred_conf = make_prediction(session_state.uploaded_image, model=MODEL, class_names=CLASSES)
    st.write(f"Prediction: {session_state.pred_class}, \
               Confidence: {session_state.pred_conf:.3f}")

    # Create feedback mechanism (building a data flywheel)
    session_state.feedback = st.selectbox(
        "çµæœæ­£ç¢ºå—ï¼Ÿ",
        ("å¹«å€‹å¿™å§", "å°ï¼", "éŒ¯äº†ï¼"))
    if session_state.feedback == "Select an option":
        pass
    elif session_state.feedback == "å°ï¼":
        st.write("è¬è¬æ‚¨çš„å›é¥‹ğŸ™")
        # Log prediction information to terminal (this could be stored in Big Query or something...)
        print(update_logger(image=session_state.image,
                            model_used=MODEL,
                            pred_class=session_state.pred_class,
                            pred_conf=session_state.pred_conf,
                            correct=True))
    elif session_state.feedback == "éŒ¯äº†ï¼":
        session_state.correct_class = st.text_input("æ­£ç¢ºçš„é¡åˆ¥æ˜¯ä»€éº¼å‘¢ï¼Ÿ")
        if session_state.correct_class:
            st.write("è¬å•¦ï¼æœ‰ä½ çš„å”åŠ©èƒ½è®“æ¨¡å‹è®Šå¾—æ›´å¥½ğŸ’ª")
            # Log prediction information to terminal (this could be stored in Big Query or something...)
            print(update_logger(image=session_state.image,
                                model_used=MODEL,
                                pred_class=session_state.pred_class,
                                pred_conf=session_state.pred_conf,
                                correct=False,
                                user_label=session_state.correct_class))
